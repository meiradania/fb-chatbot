{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1-get data\n",
    "# 2-tokenize\n",
    "# 3-map all tokens to w2v 300d vector\n",
    "# 4-average of the 300d vectors of the movie = 1 300d vector\n",
    "\n",
    "import gensim.models as gsm\n",
    "\n",
    "w2v = gsm.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45466, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \n",
       "0  Led by Woody, Andy's toys live happily in his ...  \n",
       "1  When siblings Judy and Peter discover an encha...  \n",
       "2  A family wedding reignites the ancient feud be...  \n",
       "3  Cheated on, mistreated and stepped on, the wom...  \n",
       "4  Just when George Banks has recovered from his ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1- get data\n",
    "import pandas as pd \n",
    "\n",
    "movies_metadata = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "print movies_metadata.shape\n",
    "\n",
    "\n",
    "movies_titles_description = movies_metadata.loc[:,[\"original_title\", \"overview\"]]\n",
    "movies_titles_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/dania/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>original_title_tokens</th>\n",
       "      <th>overview_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[toy, story]</td>\n",
       "      <td>[led, woody, andy, toys, live, happily, room, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[jumanji]</td>\n",
       "      <td>[siblings, judy, peter, discover, enchanted, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[grumpier, old, men]</td>\n",
       "      <td>[family, wedding, reignites, ancient, feud, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[waiting, exhale]</td>\n",
       "      <td>[cheated, mistreated, stepped, women, holding,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[father, bride, part, ii]</td>\n",
       "      <td>[george, banks, recovered, daughter, wedding, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "       original_title_tokens  \\\n",
       "0               [toy, story]   \n",
       "1                  [jumanji]   \n",
       "2       [grumpier, old, men]   \n",
       "3          [waiting, exhale]   \n",
       "4  [father, bride, part, ii]   \n",
       "\n",
       "                                     overview_tokens  \n",
       "0  [led, woody, andy, toys, live, happily, room, ...  \n",
       "1  [siblings, judy, peter, discover, enchanted, b...  \n",
       "2  [family, wedding, reignites, ancient, feud, ne...  \n",
       "3  [cheated, mistreated, stepped, women, holding,...  \n",
       "4  [george, banks, recovered, daughter, wedding, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-tokenize\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "def tokenize(text):\n",
    "    return [x for x in gensim.utils.tokenize(text, lowercase=True, deacc=True, errors=\"ignore\")\n",
    "           if x not in stopwords]\n",
    "\n",
    "\n",
    "movies_titles_description.loc[:,\"original_title_tokens\"] = movies_titles_description[\"original_title\"].map(lambda x: tokenize(str(x)))  \n",
    "movies_titles_description.loc[:,\"overview_tokens\"] = movies_titles_description[\"overview\"].map(lambda x: tokenize(str(x))) \n",
    "\n",
    "movies_titles_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103659\n",
      "1408569\n",
      "1512228\n"
     ]
    }
   ],
   "source": [
    "title_documents = [item for sublist in movies_titles_description[\"original_title_tokens\"] \n",
    "                   for item in sublist]\n",
    "overview_documents = [item for sublist in movies_titles_description[\"overview_tokens\"] \n",
    "                      for item in sublist]\n",
    "\n",
    "documents = title_documents + overview_documents\n",
    "\n",
    "print len(title_documents)\n",
    "print len(overview_documents)\n",
    "print len(documents)\n",
    "\n",
    "# save only tokens with frequency > 1 into a dictionary\n",
    "from collections import defaultdict\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for token in documents:\n",
    "    frequency[token] += 1\n",
    "\n",
    "frequent_documents = [[token for document in documents if frequency[token] > 1]\n",
    "         for document in documents]\n",
    "\n",
    "print len(frequent_documents)\n",
    "\n",
    "# final dictionary\n",
    "dictionary = corpora.Dictionary(frequent_documents)\n",
    "dictionary.save('movies.dict')\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u\"word 'lightyear' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-dec92768fccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovies_titles_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverview_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# OOV words: fastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Break the unknown word into smaller character n-grams.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/chatbot/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/chatbot/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u\"word 'lightyear' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "[w2v.wv[word] for word in movies_titles_description.overview_tokens[0]]\n",
    "\n",
    "# OOV words: fastText\n",
    "# https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "# Break the unknown word into smaller character n-grams.\n",
    "# Assemble the word vector from vectors of these ngrams.\n",
    "# The intuition: find similarity in the surface form, and assume similarity on the semantic level from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'led', u'woody', u'andy', u'toys', u'live', u'happily', u'room', u'andy', u'birthday', u'brings', u'buzz', u'lightyear', u'onto', u'scene', u'afraid', u'losing', u'place', u'andy', u'heart', u'woody', u'plots', u'buzz', u'circumstances', u'separate', u'buzz', u'woody', u'owner', u'duo', u'eventually', u'learns', u'put', u'aside', u'differences'] 33\n",
      "32 300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# OOV words: skip\n",
    "import numpy as np\n",
    "\n",
    "v = [w2v.wv[word] for word in movies_titles_description.overview_tokens[0] if word in w2v.wv.vocab]\n",
    "print movies_titles_description.overview_tokens[0], len(movies_titles_description.overview_tokens[0])\n",
    "print len(v), len(v[0])\n",
    "\n",
    "avg = np.average(v,  axis=0)\n",
    "print len(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/chatbot/lib/python2.7/site-packages/numpy/lib/function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/anaconda2/envs/chatbot/lib/python2.7/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>original_title_tokens</th>\n",
       "      <th>overview_tokens</th>\n",
       "      <th>overview_vector</th>\n",
       "      <th>original_title_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[toy, story]</td>\n",
       "      <td>[led, woody, andy, toys, live, happily, room, ...</td>\n",
       "      <td>[0.066690445, 0.09592056, 0.019028902, 0.05512...</td>\n",
       "      <td>[0.13549805, 0.097717285, -0.06188965, 0.11779...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[jumanji]</td>\n",
       "      <td>[siblings, judy, peter, discover, enchanted, b...</td>\n",
       "      <td>[0.031378668, 0.044890534, -0.028069574, 0.075...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[grumpier, old, men]</td>\n",
       "      <td>[family, wedding, reignites, ancient, feud, ne...</td>\n",
       "      <td>[0.043774772, 0.023932962, -0.023906035, 0.102...</td>\n",
       "      <td>[0.102864586, 0.12434896, 0.06526693, 0.038136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[waiting, exhale]</td>\n",
       "      <td>[cheated, mistreated, stepped, women, holding,...</td>\n",
       "      <td>[0.017270016, 0.07522348, -0.007965088, 0.0510...</td>\n",
       "      <td>[0.12060547, 0.0087890625, 0.29052734, 0.05981...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[father, bride, part, ii]</td>\n",
       "      <td>[george, banks, recovered, daughter, wedding, ...</td>\n",
       "      <td>[0.030315053, 0.037719727, -0.0469291, 0.11105...</td>\n",
       "      <td>[-0.0490036, -0.05670166, 0.019943237, 0.01733...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "       original_title_tokens  \\\n",
       "0               [toy, story]   \n",
       "1                  [jumanji]   \n",
       "2       [grumpier, old, men]   \n",
       "3          [waiting, exhale]   \n",
       "4  [father, bride, part, ii]   \n",
       "\n",
       "                                     overview_tokens  \\\n",
       "0  [led, woody, andy, toys, live, happily, room, ...   \n",
       "1  [siblings, judy, peter, discover, enchanted, b...   \n",
       "2  [family, wedding, reignites, ancient, feud, ne...   \n",
       "3  [cheated, mistreated, stepped, women, holding,...   \n",
       "4  [george, banks, recovered, daughter, wedding, ...   \n",
       "\n",
       "                                     overview_vector  \\\n",
       "0  [0.066690445, 0.09592056, 0.019028902, 0.05512...   \n",
       "1  [0.031378668, 0.044890534, -0.028069574, 0.075...   \n",
       "2  [0.043774772, 0.023932962, -0.023906035, 0.102...   \n",
       "3  [0.017270016, 0.07522348, -0.007965088, 0.0510...   \n",
       "4  [0.030315053, 0.037719727, -0.0469291, 0.11105...   \n",
       "\n",
       "                               original_title_vector  \n",
       "0  [0.13549805, 0.097717285, -0.06188965, 0.11779...  \n",
       "1                                                NaN  \n",
       "2  [0.102864586, 0.12434896, 0.06526693, 0.038136...  \n",
       "3  [0.12060547, 0.0087890625, 0.29052734, 0.05981...  \n",
       "4  [-0.0490036, -0.05670166, 0.019943237, 0.01733...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-map all tokens to w2v 300d vector\n",
    "# 4-average of the 300d vectors of the movie = 1 300d vector\n",
    "# OOV words: skip\n",
    "def avg_word2vec(tokens):\n",
    "    word2vec_embeddings = [w2v.wv[word] for word in tokens if word in w2v.wv.vocab]\n",
    "    return(np.average(word2vec_embeddings, axis=0))\n",
    "\n",
    "movies_titles_description[\"overview_vector\"] = movies_titles_description[\"overview_tokens\"].map(lambda x: avg_word2vec(x))\n",
    "movies_titles_description[\"original_title_vector\"] = movies_titles_description[\"original_title_tokens\"].map(lambda x: avg_word2vec(x))\n",
    "\n",
    "movies_titles_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OOV words: fastText\n",
    "ft = gsm.KeyedVectors.load_word2vec_format('~/Downloads/wiki.en.zip', binary=True)\n",
    "def avg_fastText(tokens):\n",
    "    fastText_embeddings = [ft.wv[word] for word in tokens]\n",
    "    return(np.average(fastText_embeddings, axis=0))\n",
    "\n",
    "movies_titles_description[\"overview_vector_fastText\"] = movies_titles_description[\"overview_tokens\"].map(lambda x: avg_fastText(x))\n",
    "movies_titles_description[\"original_title_vector_fastTex\"] = movies_titles_description[\"original_title_tokens\"].map(lambda x: avg_fastText(x))\n",
    "\n",
    "movies_titles_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_titles.to_csv(\"movies_embbedings.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:chatbot]",
   "language": "python",
   "name": "conda-env-chatbot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
